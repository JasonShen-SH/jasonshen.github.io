<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>JasonShen(沈瑞淇)-Homepage</title>
    <style>
        img {
            width: 70px;
            height: 70px;
            border-radius: 35px; /*成为圆形*/
        }
        .move-right-title{
            margin-left: 200px;
        }
        .move-right{
            margin-left: 10px; /*意思是在title已经往右之后,还要继续往右多少*/
        }

        .column1 {
            float: left; /* 左浮动 */
            width: 30%; /* 设置列的宽度为页面的一半 */
            padding: 20px; /* 添加内边距以增加列之间的间距 */
            box-sizing: border-box; /* 让内边距和边框计算在列的宽度内 */
        }

        .column2 {
            float: left; /* 左浮动 */
            width: 70%; /* 设置列的宽度为页面的一半 */
            padding: 20px; /* 添加内边距以增加列之间的间距 */
            box-sizing: border-box; /* 让内边距和边框计算在列的宽度内 */
        }

        body {
            font-family:Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;
            font-size: 15px; /* 调整字体大小 */
            line-height: 1.2; /* 调整行间距 */
        }

        /* 将图像和文本设置为行内元素 */
        .inline-content {
            display: inline;
            vertical-align: middle; /* 垂直居中对齐 */
            margin-right: 20px; /* 调整右外边距以控制元素之间的间距 */
        }
    /*https://cloud.tencent.com/developer/article/1677003 要用lfs*/
    </style>
</head>

<body>
    <div class="column1">
        <div class="move-right-title">
            <img style="margin-top: 50px; width: 160px; height:160px; border-radius: 80px;" src="pictures/me.jpg">
            <p style="font-weight: bold; font-size:20px">Ruiqi Shen (沈瑞淇) </p>
            <p style="font-size: 17px">Done is better than perfect.</p>
            <p style="font-size: 17px"><a href="https://github.com/JasonShen-SH" target="_blank">GitHub</a></p>
            <p style="font-size: 17px">Email:&nbsp;&nbsp;ruiqi.shen23@imperial.ac.uk</p>

        </div>
    </div>

    <div class="column2">

        <div class = "move-right">
            <h2>&#128218; Biography</h2>
            <p>I am a student of MSc Applied Machine Learning at Imperial College London</p>
            <p>My research interest focuses on machine vision</p>
        </div>

        <div class = "move-right">
            <h2>&#127979; Education</h2>
            <img src="pictures/imperial.jpg" class="inline-content">
            <p class="inline-content"><strong>2023.9 - 2024.9,</strong> &nbsp;&nbsp; MSc Appied Machine Learning, Imperial College London</p>
            <br>
            <img src="pictures/nus.jpg" class="inline-content">
            <p class="inline-content"><strong>2022.9 - 2023.5,</strong> &nbsp;&nbsp; Electrical and Computer Engineering, National University of Singapore Research Institute (NUSRI)</p>
            <br>
            <img src="pictures/tju.jpg" class="inline-content">
            <p class="inline-content"><strong>2019.9 - 2023.6,</strong> &nbsp;&nbsp; B.E., Qiushi Honors College, Tianjin University (111 selected out of 4804 students)</p>
        </div>

        <div class = "move-right">
            <h2>&#128187; Internships</h2>
            <p><strong>2023.5 - 2023.8,</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://zhaoxiangzhang.net/lab/" target="_blank">The BRAVE Group</a>, National Key Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences (CASIA)</p>
            <p>Focus on Multi-camera surround depth estimation</p>
            <p>1).Designed a supervised pre-trained method for multi-camera surround depth estimation by utilizing sparse depth maps generated from LiDAR, and achieved preferable depth estimation result on nuscenes dataset.</p>
            <p>2).Captured and processed the multi-camera surround view dataset of CASIA, and achieved preliminary depth estimation result by applying the method proposed in the paper.</p>
            <p>3).Designed an end-to-end two-stage heterogeneous depth estimation method by combining fisheye and pinhole cameras.</p>
            <p><a href="specifics.html">Specifics (Visualization Outcomes & Technical Documentation)</a></p>

            <p><strong>2021.7 - 2021.8,</strong> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; HUAWEI - Shanghai Kunpeng Innovation Center</p>
            <p>Developed a gesture-controlled mini-car that can perform well in night-vision environment</p>
        </div>

        <div class = "move-right">
            <h2>&#128220; Publications</h2>
            <p><u>"End-to-end Multimodal Sign Language Recognition System (upcoming)"</u>, &nbsp;&nbsp;&nbsp; -- <strong>Ruiqi Shen,</strong> Zixuan Zhang, Peiru Wu, Chengkuo Lee</p>
            <p>An end-to-end system integrating visual information and dynamic sensing is developed for recognition of American Sign Language(ASL) gestures</p>
            <p>Work at NUSRI (2022.9→2023.5), &nbsp;&nbsp; Supervisor: <a href="https://www.ece.nus.edu.sg/stfpage/elelc/" target="_blank">Prof. Chengkuo Lee</a>; &nbsp;&nbsp; 
            <p><a href="https://github.com/JasonShen-SH/Sign-language-recognition-glove-enhanced-by-visual-sensory-based-multimodality-machine-learning" target="_blank">Source Code</a> &nbsp;&nbsp; <a href="specifics2.html">Detailed introduction</a> </p>
            <p>The paper is currently being authored.</p>
        </div>

        <div class = "move-right">
            <h2>&#127942; Honors & Certificates & Experiences</h2>
            <p><strong>05/2023,</strong> &nbsp;&nbsp; Outstanding student of ECE-CLASS 2022 at NUS Research Institute </p>
            <p><strong>06/2022,</strong> &nbsp;&nbsp; Member of the Machine Vision Committee of the China Society of Images and Graphics </p>
            <p><strong>06/2022,</strong> &nbsp;&nbsp; Merit Student Scholarship of Tianjin University </p>
            <p><strong>08/2022,</strong> &nbsp;&nbsp; UNITAR Global Competency Training Programme </p>
            <p><strong>02/2021,</strong> &nbsp;&nbsp; University of Oxford: Best Teamwork award in the winter program of 'Global Challenges for the Future of Humanity' </p>
            <p><strong>IELTS:</strong> 8.0; &nbsp;&nbsp; <strong>GRE:</strong> 324+3.5; &nbsp;&nbsp; <strong>CET-6:</strong> 640</strong></p>
        </div> 


    </div>

</body>
</html>
